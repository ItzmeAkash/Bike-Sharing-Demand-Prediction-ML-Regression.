{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ItzmeAkash/Bike-Sharing-Demand-Prediction-ML-Regression./blob/main/Bike_Sharing_Demand_Prediction_ML_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**  -  Bike Sharing Demand Prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type** - Regression\n",
        "##### **Contribution** - Individual\n",
        "##### **Name** -  Akash Ps"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bike rental companies often encounter challenges in accurately predicting bike demand, crucial for optimizing inventory and pricing strategies. This project focuses on developing a supervised machine learning regression model to forecast bike demand within a specific time frame.\n",
        "\n",
        "Initially, utilizing a dataset sourced from a bike sharing company, which included rental details like bike count, rental timestamps, as well as various weather and seasonal factors, alongside other relevant variables such as holidays and operational status.\n",
        "\n",
        "Following data preprocessing and partitioning into training and test sets, the training data was used to train multiple machine learning models, exploring various architectures and hyperparameter configurations to identify the most effective model based on performance metrics.\n",
        "\n",
        "Performance evaluation of the model was conducted using metrics like mean absolute error, root mean squared error, and R-squared, demonstrating high predictive accuracy with an R-squared value of 0.88 and a mean absolute error of 2.58 on the test dataset.\n",
        "\n",
        "Furthermore, ablation studies were conducted to analyze the impact of individual features on model performance, revealing temperature, weather, and seasonality as significant factors influencing bike demand."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/ItzmeAkash/Bike-Sharing-Demand-Prediction-ML-Regression."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cities are introducing rental bikes to make it easier to get around. It's important to have enough bikes available when people need them to avoid waiting. Predicting how many bikes are needed each hour is crucial to keep a steady supply.\n",
        "\n",
        "My goal is to build a model that's really accurate and can tell us what factors affect how many bikes people want. This will help bike rental companies make better decisions about how to run their service."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "# Data Visualization\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Datetime library\n",
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sg5HK3DWuXhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/Self Projects/AlmaBetter Capstone Projects/Ml Regression/SeoulBikeData.csv'"
      ],
      "metadata": {
        "id": "yCFlIVZwuxqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "bikeDf = pd.read_csv(data_path, encoding='latin')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 5 datas\n",
        "bikeDf.head()\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bottom 5 datas\n",
        "bikeDf.tail()"
      ],
      "metadata": {
        "id": "QeNnd0BNvzUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(bikeDf.shape)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the Number of row and columns\n",
        "rows_count, columns_count = bikeDf.shape\n",
        "print(\"Number of Rows:\", rows_count)\n",
        "print(\"Number of Columns:\", columns_count)"
      ],
      "metadata": {
        "id": "KIxtRiNCwa41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting all the Columns\n",
        "bikeDf.columns"
      ],
      "metadata": {
        "id": "UK_xcWk8wVhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying All the lists\n",
        "column_names = bikeDf.columns.tolist()\n",
        "for column in column_names:\n",
        "    print(column)"
      ],
      "metadata": {
        "id": "1Ff5jgQuyPLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "bikeDf.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicates = bikeDf.duplicated()\n",
        "duplicate_count = duplicates.sum()\n",
        "unique_duplicates = len(bikeDf[duplicates])\n",
        "\n",
        "print(f\"Number of duplicate rows: {duplicate_count}, unique duplicates: {unique_duplicates}\")\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check Unique Values for Each Variable"
      ],
      "metadata": {
        "id": "3N1SfvX3_JP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for Each variables\n",
        "for column in bikeDf.columns.tolist():\n",
        "    unique_values_count = bikeDf[column].nunique()\n",
        "    print(f\"No of Unique values in {column} is {unique_values_count}\")\n"
      ],
      "metadata": {
        "id": "Pflg5M8w_PJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "missing_values_count = bikeDf.isnull().sum()\n",
        "print(missing_values_count)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total Missing Values\n",
        "total_missing_values = bikeDf.isnull().sum().sum()\n",
        "print(\"Total missing values:\", total_missing_values)\n"
      ],
      "metadata": {
        "id": "hOnr9iyqAn4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "\n",
        "# Create a heatmap of missing values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(bikeDf.isnull(), cmap='viridis', cbar=False)\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **As we can see above there are no missing value**"
      ],
      "metadata": {
        "id": "3t41rPWITpKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The dataset consists of 8,760 rows and 14 columns\n",
        "\n",
        "* The dataset contains information for each of the 8,760 hours in a year\n",
        "\n",
        "* There are no null values.\n",
        "\n",
        "* The dataset contains only unique values, meaning there are no duplicates. This ensures the data is unbiased and avoids potential issues in later analysis, like skewing results or complicating data summaries\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the list of features in the DataFrame\n",
        "features_list = bikeDf.columns.tolist()\n",
        "print(f\"Features: {features_list}\")"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "bikeDf.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date** :  The date of the day, during 365 days from 01/12/2017 to 30/11/2018\n",
        "\n",
        "**Rented Bike Count** : Number of rented bikes per hour which our dependent variable\n",
        "\n",
        "**Hour**:  The hour of the day\n",
        "\n",
        "**Temperature(°C)**: Temperature in Celsius\n",
        "\n",
        "**Humidity(%)** :  Humidity in the air\n",
        "\n",
        "**Wind Speed(m/s)** : Speed of the wind in m/s\n",
        "\n",
        "**Visibility(10m)** : Visibility\n",
        "\n",
        "**Dew point temperature(°C)** : Temperature at the beggining of the day\n",
        "\n",
        "**Solar Radiation (MJ/m2)**: It is\n",
        " measurement electromagnetic energy emitted by the Sun, including visible light, ultraviolet light, and infrared radiation\n",
        "\n",
        "**Rainfall(mm)**: Amount of raining in mm\n",
        "\n",
        "**Snowfall (cm)**: Amount of snowing in cm\n",
        "\n",
        "**Seasons** : Season of the Year\n",
        "\n",
        "**Holiday**: If the day is Holiday or Not\n",
        "\n",
        "**Funcationing Day** : if the day is a Functioning Day or Not"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "for column in bikeDf.columns.tolist():\n",
        "    unique_values_count = bikeDf[column].nunique()\n",
        "    print(f\"No of Unique values in {column} is {unique_values_count}\")\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e1JbAha6UoLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Changing column name"
      ],
      "metadata": {
        "id": "CoTkB9aj3-9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename the complex columns name\n",
        "bikeDf = bikeDf.rename(columns={'Rented Bike Count':'Rented_Bike_Count',\n",
        "                                'Temperature(°C)':'Temperature',\n",
        "                                'Humidity(%)':'Humidity',\n",
        "                                'Wind speed (m/s)':'Wind_speed',\n",
        "                                'Visibility (10m)':'Visibility',\n",
        "                                'Dew point temperature(°C)':'Dew_point_temperature',\n",
        "                                'Solar Radiation (MJ/m2)':'Solar_Radiation',\n",
        "                                'Rainfall(mm)':'Rainfall',\n",
        "                                'Snowfall (cm)':'Snowfall',\n",
        "                                'Functioning Day':'Functioning_Day'\n",
        "\n",
        "})"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new feature names\n",
        "bikeDf.columns.tolist()"
      ],
      "metadata": {
        "id": "g-t4yAqf3-WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bikeDf.head()"
      ],
      "metadata": {
        "id": "-HDBERUm4hJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the date columns into 3 column year,month day**"
      ],
      "metadata": {
        "id": "Ub53J2Sr45I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Date Columns into 3 columns Year, Month,day (Converted Object into DateTime Format)\n",
        "\n",
        "bikeDf['Date'] = pd.to_datetime(bikeDf['Date'], format=\"%d/%m/%Y\")"
      ],
      "metadata": {
        "id": "HfFG8iHy5Ehq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bikeDf.head()"
      ],
      "metadata": {
        "id": "zpAY9uhu5YEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bikeDf.info()"
      ],
      "metadata": {
        "id": "04HqamjF6yL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bikeDf['Year'] = bikeDf['Date'].dt.year\n",
        "bikeDf['Month'] = bikeDf['Date'].dt.month\n",
        "bikeDf['Day'] =  bikeDf['Date'].dt.day_name()"
      ],
      "metadata": {
        "id": "Bs21qGHs7D2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bikeDf.tail()"
      ],
      "metadata": {
        "id": "9QGgfVg_7dxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a new column of \"weekdays_weekend\" and drop the column \"Date\",\"day\",\"year\"\n",
        "bikeDf['weekdays_weekend']=bikeDf['Day'].apply(lambda x : 1 if x=='Saturday' or x=='Sunday' else 0 )\n",
        "bikeDf=bikeDf.drop(columns=['Date','Day','Year'],axis=1)"
      ],
      "metadata": {
        "id": "_NMWcx7l8DX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bikeDf.head()"
      ],
      "metadata": {
        "id": "dvKZhMiX8bBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the weekend and weekdays values\n",
        "bikeDf['weekdays_weekend'].value_counts()"
      ],
      "metadata": {
        "id": "q7XKFjE89kL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0 weekdays**\n",
        "\n",
        "**1 weekends**"
      ],
      "metadata": {
        "id": "nQ_R8wdn9tgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Changing data type"
      ],
      "metadata": {
        "id": "3guIz2nI-S1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **As \"Hour\",\"month\",\"weekdays_weekend\" column are show as a integer data type but actually it is a category data tyepe**"
      ],
      "metadata": {
        "id": "rahOdWXN-Wmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols=['Hour','Month','weekdays_weekend']\n",
        "for col in cols:\n",
        "  bikeDf[col]=bikeDf[col].astype('category')"
      ],
      "metadata": {
        "id": "uo6mZ2LU-VCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bikeDf"
      ],
      "metadata": {
        "id": "YbKmEdy3-pTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check the data type\n",
        "bikeDf.info()"
      ],
      "metadata": {
        "id": "ndx5lrUx-wJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List final Columns\n",
        "bikeDf.columns"
      ],
      "metadata": {
        "id": "7WlTRJKU-2Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qMGX6QSI-9n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Analysation of categorical variables**"
      ],
      "metadata": {
        "id": "OqOy_BsD_tjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Our dependent variable is \"Rented Bike Count,\" so we need to analyze this column along with the other columns using visualization plots. First, we'll analyze the columns with categorical data types, and then we'll proceed with those containing numerical data types.**"
      ],
      "metadata": {
        "id": "IGfXlB0v_4Yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Month**"
      ],
      "metadata": {
        "id": "jialPexEALn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "sns.barplot(data=bikeDf, x='Month', y='Rented_Bike_Count', ax=ax, capsize=0.2, palette='bright')\n",
        "ax.set(title='Count of Rented bikes according to Month')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LF9F78BWAIAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations** : - The bar plot shows that bike rentals are highest during the summer months from May to October."
      ],
      "metadata": {
        "id": "g4PCv7kUCZXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Weekdays_weekend**"
      ],
      "metadata": {
        "id": "FQeHoL9cCkOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "sns.barplot(data=bikeDf, x='weekdays_weekend', y='Rented_Bike_Count', ax=ax, capsize=0.2, palette='bright')\n",
        "ax.set(title='Count of Rented bikes acording to weekdays_weekenday')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sUkZPGpPCgYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations** :- In the above bar plot, the blue bars indicate higher bike rentals on weekdays, with only a slight difference observed on weekends."
      ],
      "metadata": {
        "id": "Z_EtV0xAC6sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "sns.pointplot(data=bikeDf, x='Hour', y='Rented_Bike_Count', hue='weekdays_weekend',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to weekdays_weekenday')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1fSuly9dDder"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations** : Based on the point plot and bar plot above, we observe that the blue bars representing weekdays show higher bike demand, likely due to commuting to and from office. Peak times are observed between 7 am to 9 am and 5 pm to 7 pm. On the other hand, the orange bars representing weekends indicate lower bike demand, especially in the morning hours. However, demand slightly increases in the evening from 4 pm to 8 pm."
      ],
      "metadata": {
        "id": "vnU2BbhJD9yC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Hour**"
      ],
      "metadata": {
        "id": "fZbB7jsoEBfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(figsize=(12,7))\n",
        "sns.barplot(data=bikeDf,x='Hour',y='Rented_Bike_Count',ax=ax,capsize=.2, palette='pastel')\n",
        "ax.set(title='Count of Rented bikes acording to Hour ')"
      ],
      "metadata": {
        "id": "mrWShOK9EFB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**\n",
        "*   The plot above displays the hourly usage of rented bikes aggregated across all months of the year.\n",
        "\n",
        "\n",
        "* Typically, people use rented bikes during their working hours, primarily from 7 am to 9 am and 5 pm to 7 pm."
      ],
      "metadata": {
        "id": "s7_OQP8VEu6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functioning Day**"
      ],
      "metadata": {
        "id": "TCNuj2brfEZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(figsize=(8,6))\n",
        "sns.barplot(data=bikeDf,x='Functioning_Day',y='Rented_Bike_Count',ax=ax,capsize=.2)\n",
        "ax.set(title='Count of Rented bikes acording to Functioning Day ')"
      ],
      "metadata": {
        "id": "ujBOwzFzEI05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(figsize=(12,7))\n",
        "sns.pointplot(data=bikeDf,x='Hour',y='Rented_Bike_Count',hue='Functioning_Day',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to Functioning Day ')"
      ],
      "metadata": {
        "id": "Kb8T1MTYfPYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "* The above bar plot and point plot illustrate the usage of rented bikes on working days versus non-working days.\n",
        "\n",
        "* Peoples don't use reneted bikes in no functioning day."
      ],
      "metadata": {
        "id": "Ryi3aZXpflfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Seasons**"
      ],
      "metadata": {
        "id": "6Pftv7ahf-eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(figsize=(12,6))\n",
        "sns.barplot(data=bikeDf,x='Seasons',y='Rented_Bike_Count',ax=ax,capsize=.2,palette='dark')\n",
        "ax.set(title='Count of Rented bikes acording to Seasons ')"
      ],
      "metadata": {
        "id": "LL54DZL1f4Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(figsize=(12,6))\n",
        "sns.pointplot(data=bikeDf,x='Hour',y='Rented_Bike_Count',hue='Seasons',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to seasons ')"
      ],
      "metadata": {
        "id": "BgkDsePwEDsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In the above bar plot and point plot\n",
        "which shows, the use of rented bike in four different seasons, and it clearly shows that,\n",
        "* In summer season the use of rented bike is high and peak time is 7am-9am and 5pm-7pm.\n",
        "* In winter season the use of rented bike is very low maybe because of snowfall, fog, cold etc."
      ],
      "metadata": {
        "id": "h5BqyYTCgZM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Holiday**"
      ],
      "metadata": {
        "id": "HXzhUaW_ghC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(figsize=(8,6))\n",
        "sns.barplot(data=bikeDf,x='Holiday',y='Rented_Bike_Count',ax=ax,capsize=.2,palette='pastel')\n",
        "ax.set(title='Count of Rented bikes acording to Holiday ')"
      ],
      "metadata": {
        "id": "LlxlC2eSD5nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(figsize=(12,6))\n",
        "sns.pointplot(data=bikeDf,x='Hour',y='Rented_Bike_Count',hue='Holiday',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to Holiday ')"
      ],
      "metadata": {
        "id": "CNMo4dx1gzSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In the above bar plot and point plot,\n",
        "the usage of rented bikes on holidays is depicted. It's clear from the plots that.\n",
        "\n",
        "*  In holiday, people uses the rented bike from 2pm-8pm"
      ],
      "metadata": {
        "id": "KGcTHUoThD-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Analysation of Numberical variables**"
      ],
      "metadata": {
        "id": "-KfaoV9BhStd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numericalFeatures= bikeDf.select_dtypes(exclude=['object','category'])\n",
        "numericalFeatures"
      ],
      "metadata": {
        "id": "SMHFYOfchdmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listing all the Numberical features\n",
        "numericalFeatures.columns.tolist()"
      ],
      "metadata": {
        "id": "BTdR2T7yh80_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysing the distribution of all numberical features\n",
        "\n",
        "n=1\n",
        "plt.figure(figsize=(15,10))\n",
        "for i in numericalFeatures.columns:\n",
        "  plt.subplot(3,3,n)\n",
        "  n=n+1\n",
        "  sns.distplot(bikeDf[i])\n",
        "  plt.title(i)\n",
        "  plt.tight_layout()"
      ],
      "metadata": {
        "id": "4sLfltEgiGyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Right skewed columns are**\n",
        "\n",
        "Rented Bike Count (Its also our Dependent variable), Wind speed (m/s), Solar Radiation (MJ/m2), Rainfall(mm), Snowfall (cm),\n",
        "\n",
        "**Left skewed columns are**\n",
        "\n",
        "\n",
        "Visibility (10m), Dew point temperature(°C)"
      ],
      "metadata": {
        "id": "P8QKyDcGiV8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find out the relation of numerical featuers with our dependent variable**"
      ],
      "metadata": {
        "id": "mALvuaQTiikl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.**Numerical VS Rented Bike Count**"
      ],
      "metadata": {
        "id": "6v-cJsrEivoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyze the relationship between \"Rented_Bike_Count\" and \"Temperature\n",
        "\n",
        "bikeDf.groupby('Temperature').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "QdsfgirEieUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation**\n",
        "\n",
        "The plot shows that people prefer riding bikes when it's around 25°C, suggesting they enjoy warmer weather."
      ],
      "metadata": {
        "id": "nu0Sl4CDjE-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyze the relationship between \"Rented_Bike_Count\" and \"Dew_point_temperature\n",
        "\n",
        "bikeDf.groupby('Dew_point_temperature').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "wkUkXdIHjHvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "From the above plot of \"Dew_point_temperature', is almost same as the 'temperature' there is some similarity present we can check it in our next step"
      ],
      "metadata": {
        "id": "omcof8Vzjpbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyze the relationship between \"Rented_Bike_Count\" and \"Solar_Radiation\n",
        "\n",
        "bikeDf.groupby('Solar_Radiation').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "iHv7DQpfjsBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "\n",
        "The plot indicates that when there's solar radiation, there's a high number of rented bikes, usually around 1000."
      ],
      "metadata": {
        "id": "9vCl4FK4j5z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyze the relationship between \"Rented_Bike_Count\" and \"Snowfall\n",
        "\n",
        "bikeDf.groupby('Snowfall').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "D1eODYbnj7jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "\n",
        "The plot shows that bike rentals are low on the y-axis. When there's more than 4 cm of snow, bike rentals decrease a lot."
      ],
      "metadata": {
        "id": "l7XcwSbDkLuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyze the relationship between \"Rented_Bike_Count\" and \"Rainfall\n",
        "\n",
        "bikeDf.groupby('Rainfall').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "uWKQp4a_kNdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "From the plot above, we notice that even when it rains heavily, the demand for rented bikes doesn't decrease. For instance, when there's 20 mm of rain, there's a significant peak in rented bikes."
      ],
      "metadata": {
        "id": "SKPc-ScWknxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyze the relationship between \"Rented_Bike_Count\" and \"Wind_speed\n",
        "\n",
        "bikeDf.groupby('Wind_speed').mean()['Rented_Bike_Count'].plot()"
      ],
      "metadata": {
        "id": "Kjov9QRhkp_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "From the plot above, we observe that the demand for rented bikes remains consistent regardless of wind speed. However, when the wind speed reaches 7 m/s, there's an increase in bike demand, suggesting that people enjoy biking when it's a bit windy."
      ],
      "metadata": {
        "id": "4QLMhHBmk1f2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **REGRESSION PLOT**"
      ],
      "metadata": {
        "id": "xRt6dzz-k9Y2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seaborn's regression plots are used to highlight patterns in a dataset during data analysis. These plots create a line between two parameters, showing their linear relationship visually."
      ],
      "metadata": {
        "id": "ShU5oVd2lGNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression plot for all the numerical features\n",
        "\n",
        "for col in numericalFeatures:\n",
        "  fig,ax=plt.subplots(figsize=(8,4))\n",
        "  sns.regplot(x=bikeDf[col],y=bikeDf['Rented_Bike_Count'],scatter_kws={\"color\": 'lightgreen'}, line_kws={\"color\": \"black\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "9010-Yahk3nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "* Looking at the regression plot above for all numerical features, we notice that the columns 'Temperature', 'Wind_speed', 'Visibility', 'Dew_point_temperature', and 'Solar_Radiation' are positively related to the target variable.\n",
        "\n",
        "\n",
        "* which means the rented bike count increases with increase of these features.\n",
        "\n",
        "\n",
        "* Rainfall','Snowfall','Humidity' these features are negatively related with the target variaable which means the rented bike count decreases when these features increase.\n"
      ],
      "metadata": {
        "id": "gIyCVkqjlqEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Normalise Rented_Bike_Count column data**"
      ],
      "metadata": {
        "id": "zLxLsW9tmInw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data normalization, also known as data pre-processing, is an important step in data mining. It involves converting the source data into a different format to make it easier to process. The main goal of data normalization is to reduce or remove duplicate data."
      ],
      "metadata": {
        "id": "vHIlce6dmUMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution plot of Rented Bike Count\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.xlabel('Rented_Bike_Count')\n",
        "plt.ylabel('Density')\n",
        "ax=sns.distplot(bikeDf['Rented_Bike_Count'],hist=True ,color=\"y\")\n",
        "ax.axvline(bikeDf['Rented_Bike_Count'].mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(bikeDf['Rented_Bike_Count'].median(), color='black', linestyle='dashed', linewidth=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qRC3xaSVmL4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "The above graph shows that, Rented Bike Count has moderate right skewness. Since the assumption of linear regression is that 'the distribution of dependent variable has to be normal', so we should perform some operation to make it normaL"
      ],
      "metadata": {
        "id": "lSR2ckNSmfkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding Outliers and treatment**"
      ],
      "metadata": {
        "id": "tQx4bK8Bmlan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot for Rented bike Count to check outliers\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.ylabel('Rented_Bike_Count')\n",
        "sns.boxplot(x=bikeDf['Rented_Bike_Count'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O0j5YgS1moXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treat outliers by capping values at specified thresholds\n",
        "bikeDf['Rainfall'] = bikeDf['Rainfall'].clip(upper=4)\n",
        "bikeDf['Solar_Radiation'] = bikeDf['Solar_Radiation'].clip(upper=2.5)\n",
        "bikeDf['Snowfall'] = bikeDf['Snowfall'].clip(upper=2)\n",
        "bikeDf['Wind_speed'] = bikeDf['Wind_speed'].clip(upper=4)"
      ],
      "metadata": {
        "id": "lto6s1Z5mnRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "we have applied outlier treatment techniques to the dataset by replacing the outliers with the maximum values."
      ],
      "metadata": {
        "id": "2v6s3PdUnCfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying square root to Rented Bike Count to improve skewness\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.xlabel('Rented Bike Count')\n",
        "plt.ylabel('Density')\n",
        "\n",
        "ax=sns.distplot(np.sqrt(bikeDf['Rented_Bike_Count']), color=\"y\")\n",
        "ax.axvline(np.sqrt(bikeDf['Rented_Bike_Count']).mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(np.sqrt(bikeDf['Rented_Bike_Count']).median(), color='black', linestyle='dashed', linewidth=2)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1SjXQXIKnC-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have generic rule of applying Square root for the skewed variable in order to make it normal .After applying Square root to the skewed Rented Bike Count, here we get almost normal distribution."
      ],
      "metadata": {
        "id": "Jw1W5q-_nIkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#After applying sqrt on Rented Bike Count check wheater we still have outliers\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.ylabel('Rented_Bike_Count')\n",
        "sns.boxplot(x=np.sqrt(bikeDf['Rented_Bike_Count']))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n05pnPsEmgJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "****"
      ],
      "metadata": {
        "id": "gvR3hF5ZnWzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations**\n",
        "\n",
        "After applying Square root to the Rented Bike Count column, we find that there is no outliers present."
      ],
      "metadata": {
        "id": "WCWaLpOqnYkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bikeDf.corr()"
      ],
      "metadata": {
        "id": "8IBKKT-ujAQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Checking of Correlation between variables"
      ],
      "metadata": {
        "id": "qOTkiRi3n2wX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Checking of Correlation between variables**"
      ],
      "metadata": {
        "id": "yLPuhmO9oAK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking in OLS Model"
      ],
      "metadata": {
        "id": "Er2tFD7aoFc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ordinary least squares (OLS) regression is a statistical method of analysis that estimates the relationship between one or more independent variables and a dependent variable"
      ],
      "metadata": {
        "id": "Y3LDh6hnoLB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#assign the 'x','y' value\n",
        "import statsmodels.api as sm\n",
        "X = bikeDf[[ 'Temperature','Humidity',\n",
        "       'Wind_speed', 'Visibility','Dew_point_temperature',\n",
        "       'Solar_Radiation', 'Rainfall', 'Snowfall']]\n",
        "Y = bikeDf['Rented_Bike_Count']\n",
        "bikeDf.head()"
      ],
      "metadata": {
        "id": "g6e5jxx1oLlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add a constant column\n",
        "X = sm.add_constant(X)\n",
        "X"
      ],
      "metadata": {
        "id": "YGf3DvNHoHft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## fit an OLS model\n",
        "\n",
        "model= sm.OLS(Y, X).fit()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5WrskPVXoXrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* R sqauare and Adj Square are near to each other. 40% of variance in the Rented Bike count is explained by the model.\n",
        "\n",
        "* For F statistic , P value is less than 0.05 for 5% levelof significance.\n",
        "\n",
        "* P value of dew point temp and visibility are very high and they are not significant.\n",
        "\n",
        "* Omnibus tests the skewness and kurtosis of the residuals. Here the value of Omnibus is high., it shows we have skewness in our data.\n",
        "\n",
        "* The condition number is large, 3.11e+04. This might indicate that there are strong multicollinearity or other numerical problems\n",
        "\n",
        "* Durbin-Watson tests for autocorrelation of the residuals. Here value is less than 0.5. We can say that there exists a positive auto correlation among the variables."
      ],
      "metadata": {
        "id": "mTvrzys1ob0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X.corr()"
      ],
      "metadata": {
        "id": "qDJmUxB2oi4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* From the OLS model we find that the 'Temperature' and 'Dew_point_temperature' are highly correlated so we need to drop one of them.\n",
        "* For droping them we check the (P>|t|) value from above table and we can see that the 'Dew_point_temperature' value is higher so we need to drop Dew_point_temperature column\n",
        "*For clarity, we use visualisation i.e heatmap in next step"
      ],
      "metadata": {
        "id": "qRqzqAQjo-7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Heatmap**"
      ],
      "metadata": {
        "id": "_zUzn8CDpFGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking correlation using heatmap\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.heatmap(bikeDf.corr(),cmap='PiYG',annot=True)\n"
      ],
      "metadata": {
        "id": "-tNLWDvko-AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**We can observe on the heatmap that on the target variable line, the most positively correlated variables to the rent are:**\n",
        "\n",
        "* the temperature\n",
        "* the dew point temperature\n",
        "* the solar radiation\n",
        "\n",
        "\n",
        "**And most negatively correlated variables are:**\n",
        "\n",
        "* humidity\n",
        "* rainfall\n",
        "\n",
        "\n",
        "* From the above correlation heatmap, We see that there is a positive correlation between columns 'Temperature' and 'Dew point temperature' i.e 0.91 so even if we drop this column then it won't affect the outcome of our analysis. And they have the same variations, so we can drop the column 'Dew point temperature(°C)'"
      ],
      "metadata": {
        "id": "KZuYkhW4pMCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# drop the Dew point temperature column\n",
        "bikeDf=bikeDf.drop(['Dew_point_temperature'],axis=1)"
      ],
      "metadata": {
        "id": "nQvrdNmmpLef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bikeDf.info()"
      ],
      "metadata": {
        "id": "H6iI-zmDptFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handleing Categorical Values"
      ],
      "metadata": {
        "id": "6FaCh2Fop-Iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot Encoding**"
      ],
      "metadata": {
        "id": "k1PlTxK9qEVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# all categorical features to a variable\n",
        "categorical_features=list(bikeDf.select_dtypes(['object','category']).columns)\n",
        "categorical_features=pd.Index(categorical_features)\n",
        "categorical_features\n"
      ],
      "metadata": {
        "id": "mLL9UBgIqDJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_df_copy = bikeDf\n",
        "\n",
        "def one_hot_encoding(data, column):\n",
        "    data = pd.concat([data, pd.get_dummies(data[column], prefix=column, drop_first=True)], axis=1)\n",
        "    data = data.drop([column], axis=1)\n",
        "    return data\n",
        "\n",
        "for col in categorical_features:\n",
        "    bike_df_copy = one_hot_encoding(bike_df_copy, col)\n",
        "bike_df_copy.head()"
      ],
      "metadata": {
        "id": "PTqHGcn0p8w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Model Training**"
      ],
      "metadata": {
        "id": "YF3M5i8ZrZWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test split for regression"
      ],
      "metadata": {
        "id": "yMpXAtQsreYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = bike_df_copy.drop(columns=['Rented_Bike_Count'], axis=1)\n",
        "y = np.sqrt(bike_df_copy['Rented_Bike_Count'])"
      ],
      "metadata": {
        "id": "HLDw2CfHrcti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "HYKaAVEfrj1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y.head()"
      ],
      "metadata": {
        "id": "X9kjDSNHrlK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting the data into Train and test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25, random_state=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "WXeNRWFFrmnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression"
      ],
      "metadata": {
        "id": "EN-HgRhisBAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg= LinearRegression().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6F3er7eWsDOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the score\n",
        "reg.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "65m3Gs-hsG3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the coefficeint\n",
        "reg.coef_"
      ],
      "metadata": {
        "id": "ExKmYJcesIm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "y_pred = reg.predict(X_train)\n",
        "y_pred_test = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "pIqNtupQsQsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "#calculate MSE\n",
        "MSE_lr= mean_squared_error((y_train), (y_pred))\n",
        "print(\"MSE :\",MSE_lr)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_lr=np.sqrt(MSE_lr)\n",
        "print(\"RMSE :\",RMSE_lr)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_lr= mean_absolute_error(y_train, y_pred)\n",
        "print(\"MAE :\",MAE_lr)\n",
        "\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_lr= r2_score(y_train, y_pred)\n",
        "print(\"R2 :\",r2_lr)\n",
        "Adjusted_R2_lr = (1-(1-r2_score(y_train, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n"
      ],
      "metadata": {
        "id": "KqiY1223sa4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks like our train set's r2 score value is 0.79**"
      ],
      "metadata": {
        "id": "-9kisDXasxRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Linear regression ',\n",
        "       'MAE':round((MAE_lr),3),\n",
        "       'MSE':round((MSE_lr),3),\n",
        "       'RMSE':round((RMSE_lr),3),\n",
        "       'R2_score':round((r2_lr),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_lr ),2)\n",
        "       }\n",
        "training_df=pd.DataFrame(dict1,index=[1])\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_lr= mean_squared_error(y_test, y_pred_test)\n",
        "print(\"MSE :\",MSE_lr)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_lr=np.sqrt(MSE_lr)\n",
        "print(\"RMSE :\",RMSE_lr)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_lr= mean_absolute_error(y_test, y_pred_test)\n",
        "print(\"MAE :\",MAE_lr)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_lr= r2_score((y_test), (y_pred_test))\n",
        "print(\"R2 :\",r2_lr)\n",
        "Adjusted_R2_lr = (1-(1-r2_score((y_test), (y_pred_test)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n",
        "print(\"Adjusted R2 :\",Adjusted_R2_lr )"
      ],
      "metadata": {
        "id": "vFiBM15ms4JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The test set's r2_score is 0.80**"
      ],
      "metadata": {
        "id": "fxb6ke2QtB5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Linear regression ',\n",
        "       'MAE':round((MAE_lr),3),\n",
        "       'MSE':round((MSE_lr),3),\n",
        "       'RMSE':round((RMSE_lr),3),\n",
        "       'R2_score':round((r2_lr),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_lr ),2)\n",
        "       }\n",
        "test_df=pd.DataFrame(dict2,index=[1])"
      ],
      "metadata": {
        "id": "G4M3CXzbtAzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity - Residual plot\n",
        "plt.scatter((y_pred_test),(y_test)-(y_pred_test))\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1yw4jwoMtHW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual Price vs predicte for Linear Regression plot\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(y_pred_test)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aW3XUG4dtJvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RIDGE REGRESSION**"
      ],
      "metadata": {
        "id": "y3j1uV2StWkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#import the packages\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge= Ridge(alpha=0.1)\n",
        "\n",
        "\n",
        "#FIT THE MODEL\n",
        "ridge.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Zh1_EbYDtZU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#check the score\n",
        "ridge.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "csD54GoNteZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_ridge=ridge.predict(X_train)\n",
        "y_pred_test_ridge=ridge.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "yv-u_sYitghK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_train_ridge"
      ],
      "metadata": {
        "id": "ugaOluD5tiPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test_ridge"
      ],
      "metadata": {
        "id": "UKxIIW9btkco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "#calculate MSE\n",
        "MSE_r= mean_squared_error((y_train), (y_pred_train_ridge))\n",
        "print(\"MSE :\",MSE_r)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_r=np.sqrt(MSE_r)\n",
        "print(\"RMSE :\",RMSE_r)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_r= mean_absolute_error(y_train, y_pred_train_ridge)\n",
        "print(\"MAE :\",MAE_r)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_r= r2_score(y_train, y_pred_train_ridge)\n",
        "print(\"R2 :\",r2_r)\n",
        "Adjusted_R2_r=(1-(1-r2_score(y_train, y_pred_train_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n"
      ],
      "metadata": {
        "id": "uNyBwL7AtoXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks like our train set's r2 score value is 0.79**"
      ],
      "metadata": {
        "id": "-ePAvpoRttUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Ridge regression ',\n",
        "       'MAE':round((MAE_r),3),\n",
        "       'MSE':round((MSE_r),3),\n",
        "       'RMSE':round((RMSE_r),3),\n",
        "       'R2_score':round((r2_r),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_r ),2)}\n",
        "training_df=training_df.append(dict1,ignore_index=True)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_r= mean_squared_error(y_test, y_pred_test_ridge)\n",
        "print(\"MSE :\",MSE_r)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_r=np.sqrt(MSE_r)\n",
        "print(\"RMSE :\",RMSE_r)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_r= mean_absolute_error(y_test, y_pred_test_ridge)\n",
        "print(\"MAE :\",MAE_r)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_r= r2_score((y_test), (y_pred_test_ridge))\n",
        "print(\"R2 :\",r2_r)\n",
        "Adjusted_R2_r=(1-(1-r2_score((y_test), (y_pred_test_ridge)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_ridge)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n"
      ],
      "metadata": {
        "id": "kyJsyBN-tvWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The r2_score for the test set is 0.80."
      ],
      "metadata": {
        "id": "b7PbR-t9t39Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Ridge regression ',\n",
        "       'MAE':round((MAE_r),3),\n",
        "       'MSE':round((MSE_r),3),\n",
        "       'RMSE':round((RMSE_r),3),\n",
        "       'R2_score':round((r2_r),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_r ),2)}\n",
        "test_df=test_df.append(dict2,ignore_index=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VIMPAwsGt8PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Heteroscadacity - Residual plot\n",
        "plt.scatter((y_pred_test_ridge),(y_test)-(y_pred_test_ridge))\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k7HaWSSft6mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Plot the figure\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot((y_pred_test_ridge))\n",
        "plt.plot((np.array(y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iml1mxOwt_I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ELASTIC NET REGRESSION**"
      ],
      "metadata": {
        "id": "eUBS313WuCP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#import the packages\n",
        "from sklearn.linear_model import ElasticNet\n",
        "#a * L1 + b * L2\n",
        "#alpha = a + b and l1_ratio = a / (a + b)\n",
        "elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "\n",
        "\n",
        "#FIT THE MODEL\n",
        "elasticnet.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "CBQoc990uFR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elasticnet.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "YL5zBsa5uGu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_en=elasticnet.predict(X_train)\n",
        "y_pred_test_en=elasticnet.predict(X_test)\n"
      ],
      "metadata": {
        "id": "JOd1kwA-uIMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(y_pred_train_en)\n",
        "print(y_pred_test_en)"
      ],
      "metadata": {
        "id": "SHkrYJp-uJZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "#calculate MSE\n",
        "MSE_e= mean_squared_error((y_train), (y_pred_train_en))\n",
        "print(\"MSE :\",MSE_e)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e=np.sqrt(MSE_e)\n",
        "print(\"RMSE :\",RMSE_e)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e= mean_absolute_error(y_train, y_pred_train_en)\n",
        "print(\"MAE :\",MAE_e)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e= r2_score(y_train, y_pred_train_en)\n",
        "print(\"R2 :\",r2_e)\n",
        "Adjusted_R2_e=(1-(1-r2_score(y_train, y_pred_train_en))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_en))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n"
      ],
      "metadata": {
        "id": "rAm0S_s_uMU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Elastic net regression ',\n",
        "       'MAE':round((MAE_e),3),\n",
        "       'MSE':round((MSE_e),3),\n",
        "       'RMSE':round((RMSE_e),3),\n",
        "       'R2_score':round((r2_e),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_e ),2)}\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "pVcaCUTwuP5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_e= mean_squared_error(y_test, y_pred_test_en)\n",
        "print(\"MSE :\",MSE_e)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e=np.sqrt(MSE_e)\n",
        "print(\"RMSE :\",RMSE_e)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e= mean_absolute_error(y_test, y_pred_test_en)\n",
        "print(\"MAE :\",MAE_e)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e= r2_score((y_test), (y_pred_test_en))\n",
        "print(\"R2 :\",r2_e)\n",
        "Adjusted_R2_e=(1-(1-r2_score((y_test), (y_pred_test_en)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_en)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "\n"
      ],
      "metadata": {
        "id": "kt792RDuuSI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The r2_score for the test set is 0.63.**"
      ],
      "metadata": {
        "id": "UdrhSHKiuUVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Elastic net regression Test',\n",
        "       'MAE':round((MAE_e),3),\n",
        "       'MSE':round((MSE_e),3),\n",
        "       'RMSE':round((RMSE_e),3),\n",
        "       'R2_score':round((r2_e),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_e ),2)}\n",
        "test_df=test_df.append(dict2,ignore_index=True)\n"
      ],
      "metadata": {
        "id": "5NjEO5CEuWIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### Heteroscadacity- Residual plo\n",
        "plt.scatter((y_pred_test_en),(y_test)-(y_pred_test_en))\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UCSzFQEluXwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(np.array(y_pred_test_en))\n",
        "plt.plot((np.array(y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r6ixnN5GuZsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **DECISION TREE**"
      ],
      "metadata": {
        "id": "2BMUb40zumOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "decision_regressor = DecisionTreeRegressor(criterion='friedman_mse', max_depth=8,\n",
        "                      max_features=9, max_leaf_nodes=100,)\n",
        "decision_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "riLojdFrunhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_d = decision_regressor.predict(X_train)\n",
        "y_pred_test_d = decision_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "j2GnwudYuraI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(y_pred_train_d)\n",
        "print(y_pred_test_d)"
      ],
      "metadata": {
        "id": "EomH30vQusvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "print(\"Model Score:\",decision_regressor.score(X_train,y_train))\n",
        "\n",
        "#calculate MSE\n",
        "MSE_d= mean_squared_error(y_train, y_pred_train_d)\n",
        "print(\"MSE :\",MSE_d)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_d=np.sqrt(MSE_d)\n",
        "print(\"RMSE :\",RMSE_d)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_d= mean_absolute_error(y_train, y_pred_train_d)\n",
        "print(\"MAE :\",MAE_d)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_d= r2_score(y_train, y_pred_train_d)\n",
        "print(\"R2 :\",r2_d)\n",
        "Adjusted_R2_d=(1-(1-r2_score(y_train, y_pred_train_d))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_d))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "\n"
      ],
      "metadata": {
        "id": "K2x7jfhZuu6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks like our train set's r2 score value is 0.68**"
      ],
      "metadata": {
        "id": "zupdXAhduy4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Dicision tree regression ',\n",
        "       'MAE':round((MAE_d),3),\n",
        "       'MSE':round((MSE_d),3),\n",
        "       'RMSE':round((RMSE_d),3),\n",
        "       'R2_score':round((r2_d),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_d),2)\n",
        "      }\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "-ibuoWuou3sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "#calculate MSE\n",
        "MSE_d= mean_squared_error(y_test, y_pred_test_d)\n",
        "print(\"MSE :\",MSE_d)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_d=np.sqrt(MSE_d)\n",
        "print(\"RMSE :\",RMSE_d)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_d= mean_absolute_error(y_test, y_pred_test_d)\n",
        "print(\"MAE :\",MAE_d)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_d= r2_score((y_test), (y_pred_test_d))\n",
        "print(\"R2 :\",r2_d)\n",
        "Adjusted_R2_d=(1-(1-r2_score((y_test), (y_pred_test_d)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_d)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "\n"
      ],
      "metadata": {
        "id": "YEBTEXEeu7H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The r2_score for the test set is 0.65."
      ],
      "metadata": {
        "id": "j5EjC6Z2vAeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Dicision tree regression ',\n",
        "       'MAE':round((MAE_d),3),\n",
        "       'MSE':round((MSE_d),3),\n",
        "       'RMSE':round((RMSE_d),3),\n",
        "       'R2_score':round((r2_d),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_d),2)\n",
        "      }\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "6EKOqvdIu_G3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "### Heteroscadacity - Residual plot\n",
        "plt.scatter((y_pred_test_d),(y_test)-(y_pred_test_d))\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vNavZwhgvE4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#Plot the figure\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot((np.array(y_pred_test_d)))\n",
        "plt.plot(np.array((y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XIXyPO9UvGyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forest**"
      ],
      "metadata": {
        "id": "7fwzXrrBvdIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rfModel = RandomForestRegressor()\n",
        "\n",
        "rfModel.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "tgRyWHLM_Z3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions on Training and testing data\n",
        "\n",
        "rf_y_pred_train = rfModel.predict(X_train)\n",
        "rf_y_pred_test = rfModel.predict(X_test)"
      ],
      "metadata": {
        "id": "rtV5yqzN_x8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rf_y_pred_train)\n",
        "print(rf_y_pred_test)"
      ],
      "metadata": {
        "id": "0uzHClv8AIYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
        "\n",
        "print(\"Model Score\", rfModel.score(X_train,y_train))\n",
        "\n",
        "# Calculate MSE\n",
        "\n",
        "MSE_rf = mean_squared_error(y_train,rf_y_pred_train)\n",
        "print(\"MSE:\", MSE_rf)\n",
        "\n",
        "\n",
        "# Calculate RMSE\n",
        "RMSE_rf = np.sqrt(MSE_rf)\n",
        "print(\"RMSE\", RMSE_rf)\n",
        "\n",
        "# Calculate MAE\n",
        "MAE_rf = mean_absolute_error(y_train,rf_y_pred_train)\n",
        "print(\"MAE\",MAE_rf)\n",
        "\n",
        "\n",
        "# Calculate R2 and adjusted R2\n",
        "\n",
        "r2_rf = r2_score(y_train,rf_y_pred_train)\n",
        "print(\"R2 :\", r2_rf)\n",
        "\n",
        "\n",
        "Adjusted_R2_rf = (1-(1-r2_score(y_train, rf_y_pred_train))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, rf_y_pred_train))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "OOA89EgUAN1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Our train set's r2 score value is 0.98 that means**"
      ],
      "metadata": {
        "id": "4W0_LMmnCOqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict1={'Model':'Random forest regression ',\n",
        "       'MAE':round((MAE_rf),3),\n",
        "       'MSE':round((MSE_rf),3),\n",
        "       'RMSE':round((RMSE_rf),3),\n",
        "       'R2_score':round((r2_rf),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_rf ),2)}\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "toUYugNlBbQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#with testing dataset\n",
        "\n",
        "#calculate MSE\n",
        "MSE_rf= mean_squared_error(y_test, rf_y_pred_test)\n",
        "print(\"MSE :\",MSE_rf)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_rf=np.sqrt(MSE_rf)\n",
        "print(\"RMSE :\",RMSE_rf)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_rf= mean_absolute_error(y_test, rf_y_pred_test)\n",
        "print(\"MAE :\",MAE_rf)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_rf= r2_score((y_test), (rf_y_pred_test))\n",
        "print(\"R2 :\",r2_rf)\n",
        "Adjusted_R2_rf=(1-(1-r2_score((y_test), (rf_y_pred_test)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (rf_y_pred_test)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        ""
      ],
      "metadata": {
        "id": "HTFz_i18CrFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The r2_score for the test set is 0.91.**"
      ],
      "metadata": {
        "id": "qpMMDr9kC2dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the testset in aa dataframe for future camparison\n",
        "dict2={'Model':'Random forest regression ',\n",
        "      'MAE':round((MAE_rf),3),\n",
        "       'MSE':round((MSE_rf),3),\n",
        "       'RMSE':round((RMSE_rf),3),\n",
        "       'R2_score':round((r2_rf),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_rf ),2)}\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "Zvlfjb8wC332"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter((rf_y_pred_test),(y_test)-(rf_y_pred_test))\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I17LDw89DGQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfModel.feature_importances_"
      ],
      "metadata": {
        "id": "pD-uyPmXDNDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikvm98NoDQ3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **FEATURES STORED**"
      ],
      "metadata": {
        "id": "R0iYfMk1DU9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importances = rfModel.feature_importances_\n",
        "\n",
        "importance_dict = {'Feature' : list(X_train.columns),\n",
        "                   'Feature Importance' : importances}\n",
        "\n",
        "importance_df = pd.DataFrame(importance_dict)"
      ],
      "metadata": {
        "id": "VUkHgX4yDW6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df.head()"
      ],
      "metadata": {
        "id": "PdfKAZYfDdAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df['Feature Importance'] = round(importance_df['Feature Importance'],2)"
      ],
      "metadata": {
        "id": "PVqd4GBDDg49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df.sort_values(by=['Feature Importance'],ascending=False)"
      ],
      "metadata": {
        "id": "WCPasW2cDjs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfModel.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "AUKsDG5ZEJYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features = X_train.columns\n",
        "importances = rfModel.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        ""
      ],
      "metadata": {
        "id": "0C8myG2ZEQqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(10,20))\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='blue', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')"
      ],
      "metadata": {
        "id": "wPLtT7TXEVi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hyperparameter tuning**"
      ],
      "metadata": {
        "id": "vxDy_ZeQEvWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Number of trees\n",
        "n_estimators = [50,80,100]\n",
        "\n",
        "# Maximum depth of trees\n",
        "max_depth = [4,6,8]\n",
        "\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [50,100,150]\n",
        "\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [40,50]\n",
        "\n",
        "# HYperparameter Grid\n",
        "param_dict = {'n_estimators' : n_estimators,\n",
        "              'max_depth' : max_depth,\n",
        "              'min_samples_split' : min_samples_split,\n",
        "              'min_samples_leaf' : min_samples_leaf}"
      ],
      "metadata": {
        "id": "Jp4VDB1qEou2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing Gradient Boosting Regressor**"
      ],
      "metadata": {
        "id": "KaYZoBZrE5x_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor"
      ],
      "metadata": {
        "id": "9pbi6rjoE7-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_model = GradientBoostingRegressor()\n",
        "\n",
        "\n",
        "param_dict = {\n",
        "    'learning_rate':[0.1,0.01],\n",
        "    'n_estimators':[50,100],\n",
        "    'max_depth': [3,5]\n",
        "}\n",
        "\n",
        "gb_grid = GridSearchCV(estimator=gb_model,\n",
        "                       param_grid=param_dict,\n",
        "                       cv=3, verbose=2,n_jobs=-1)\n",
        "\n",
        "\n",
        "gb_grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "ESGEctd5E_12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_grid.best_estimator_"
      ],
      "metadata": {
        "id": "9SoD17TJFkfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_optimal_model = gb_grid.best_estimator_"
      ],
      "metadata": {
        "id": "texuoUk1FoDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_grid.best_params_"
      ],
      "metadata": {
        "id": "a_t6pKpLE3g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on train and test data\n",
        "\n",
        "y_pred_train_g_g = gb_optimal_model.predict(X_train)\n",
        "y_pred_g_g= gb_optimal_model.predict(X_test)"
      ],
      "metadata": {
        "id": "Eus_Cg2wFu76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Model Score:\",gb_optimal_model.score(X_train,y_train))\n",
        "MSE_gbh= mean_squared_error(y_train, y_pred_train_g_g)\n",
        "print(\"MSE :\",MSE_gbh)\n",
        "\n",
        "RMSE_gbh=np.sqrt(MSE_gbh)\n",
        "print(\"RMSE :\",RMSE_gbh)\n",
        "\n",
        "\n",
        "MAE_gbh= mean_absolute_error(y_train, y_pred_train_g_g)\n",
        "print(\"MAE :\",MAE_gbh)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "r2_gbh= r2_score(y_train, y_pred_train_g_g)\n",
        "print(\"R2 :\",r2_gbh)\n",
        "Adjusted_R2_gbh = (1-(1-r2_score(y_train, y_pred_train_g_g))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_g_g))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n"
      ],
      "metadata": {
        "id": "_AMjvzE9Fynu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Looks like our train set's r2 score value is 0.94**"
      ],
      "metadata": {
        "id": "v6UgCJmYF1aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict1={'Model':'Gradient Boosting gridsearchcv ',\n",
        "       'MAE':round((MAE_gbh),3),\n",
        "       'MSE':round((MSE_gbh),3),\n",
        "       'RMSE':round((RMSE_gbh),3),\n",
        "       'R2_score':round((r2_gbh),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_gbh ),2)\n",
        "      }\n",
        "training_df=training_df.append(dict1,ignore_index=True)"
      ],
      "metadata": {
        "id": "855OfYLgF37O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "MSE_gbh= mean_squared_error(y_test, y_pred_g_g)\n",
        "print(\"MSE :\",MSE_gbh)\n",
        "\n",
        "RMSE_gbh=np.sqrt(MSE_gbh)\n",
        "print(\"RMSE :\",RMSE_gbh)\n",
        "\n",
        "\n",
        "MAE_gbh= mean_absolute_error(y_test, y_pred_g_g)\n",
        "print(\"MAE :\",MAE_gbh)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "r2_gbh= r2_score((y_test), (y_pred_g_g))\n",
        "print(\"R2 :\",r2_gbh)\n",
        "Adjusted_R2_gbh = (1-(1-r2_score(y_test, y_pred_g_g))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_g_g)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "sDtLwySvF6di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the test set metrics value in a dataframe for later comparison\n",
        "dict2={'Model':'Gradient Boosting gridsearchcv ',\n",
        "       'MAE':round((MAE_gbh),3),\n",
        "       'MSE':round((MSE_gbh),3),\n",
        "       'RMSE':round((RMSE_gbh),3),\n",
        "       'R2_score':round((r2_gbh),3),\n",
        "       'Adjusted R2':round((Adjusted_R2_gbh ),2)\n",
        "      }\n",
        "test_df=test_df.append(dict2,ignore_index=True)"
      ],
      "metadata": {
        "id": "lNsWUnu6F9LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter((y_pred_g_g),(y_test)-(y_pred_g_g))\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kAwzxIiSF_Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gb_optimal_model.feature_importances_"
      ],
      "metadata": {
        "id": "pImntB_RGBnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**FEATURES STORED**"
      ],
      "metadata": {
        "id": "MJwRhtE4GDwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importances = gb_optimal_model.feature_importances_\n",
        "\n",
        "importance_dict = {'Feature' : list(X_train.columns),\n",
        "                   'Feature Importance' : importances}\n",
        "\n",
        "importance_df = pd.DataFrame(importance_dict)\n",
        ""
      ],
      "metadata": {
        "id": "_pu1HkhJGFQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df['Feature Importance'] = round(importance_df['Feature Importance'],2)"
      ],
      "metadata": {
        "id": "oPh3m4eqGIS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "importance_df.head()"
      ],
      "metadata": {
        "id": "NDTj150cGKcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "importance_df.sort_values(by=['Feature Importance'],ascending=False)"
      ],
      "metadata": {
        "id": "z1SgXkHeGK3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "W4H3Mu3KGNJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = X_train.columns\n",
        "importances = gb_model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        ""
      ],
      "metadata": {
        "id": "U6obY2o0GRL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(10,20))\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='blue', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n"
      ],
      "metadata": {
        "id": "9IQjedDXGTcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During our Analysis, we looked closely at all the different parts of our data. We started by checking out the main thing we're interested in, which is how many bikes are being rented. Then, we made some changes to the data to make it easier to work with.\n",
        "\n",
        "Next, we took a closer look at the different types of information in our data. Some things, like whether it's raining or not, are words, and some things, like how many bikes are rented, are numbers. We figured out which words were most common and which numbers were related to each other. We also got rid of some numbers that weren't very helpful.\n",
        "\n",
        "After that, we used some fancy computer programs to try to predict how many bikes would be rented using the information we have. We tried seven different ways of doing this. We also tweaked the settings to make our predictions as good as possible.\n",
        "\n",
        "When we finished, we found out some interesting things about how accurate our predictions were."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result=pd.concat([training_df,test_df],keys=['Training set','Test set'])\n",
        "result"
      ],
      "metadata": {
        "id": "fh4CiVLQGnac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I train the a model to guess how many bikes will be rented based on the weather. First, we study the data to see if there are any missing or unusual values, and if i find any, i fix them. Then, i check which parts of the data are most important and make some changes to make it easier for the model to understand\n",
        "\n",
        "* Gradient Boosting gridsearchcv model shows promising result with R2 score of 0.91, therefore it can be used to solve this problem.\n",
        "\n",
        "\n",
        "* Temperatue, Functioning_Day_Yes, Humidity, Rainfall and Solar radiation are major driving factors for the Bike rent demand.\n",
        "\n",
        "\n",
        "* Bike demand shows peek around 8-9 AM in the morning and 6 - 7pm in the evening.\n",
        "\n",
        "\n",
        "* People prefer to rent bike more in summer than in winter.\n",
        "\n",
        "* Bike demand is more on clear days than on snowy or rainy days.\n",
        "\n",
        "* Temperature range from 22 to 25(°C) has more demand for bike\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Even though our analysis is helpful, remember that the data changes over time. Things like temperature and wind speed can vary, which might cause our model to not work as well sometimes. Because machine learning is always changing, it's important to keep learning and be ready for surprises. Knowing a lot about machine learning will definitely help you stay ahead in the future"
      ],
      "metadata": {
        "id": "IZNAHqCqHBXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}